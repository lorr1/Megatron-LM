# TODO(karan): this file should just contain architecture related parameters, no training params etc.

# GPT-2 arguments
num_layers: 24
hidden_size: 1024
num_attention_heads: 16
seq_length: 1024
max_position_embeddings: 1024
batch_size: 16
lr: 0.00015
lr_decay_iters: 320000
lr_decay_style: cosine
warmup: .01
fp16: True
